{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating contextual data for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from helper_functions import parsing\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/documents_with_ids.json\") as f:\n",
    "    documents = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below:\n",
    "- Chunk out tables\n",
    "- If text is longer than 3000 characters, stop at the last sentence before exceeding the 3000th character and start a new chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Splits the text into sentences based on periods, but ignores decimals.\"\"\"\n",
    "\n",
    "    # Regex to split by period followed by space or end of string, but not decimal points in numbers\n",
    "    sentence_endings = re.compile(r\"(?<!\\d)\\.(?=\\s|$)\")\n",
    "\n",
    "    # Split text into sentences at the appropriate places (before periods, not in decimals)\n",
    "    sentences = sentence_endings.split(text)\n",
    "\n",
    "    # Rebuild the sentences, appending the period that was removed\n",
    "    sentences = [\n",
    "        sentences[i] + \".\" if i < len(sentences) - 1 else sentences[i]\n",
    "        for i in range(len(sentences))\n",
    "    ]  # noqa: E501\n",
    "\n",
    "    # Remove any trailing empty strings from split operation\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "\n",
    "def separate_tables_from_text(document, chunk_size_limit: int = 3000):\n",
    "    \"\"\"\n",
    "    Separate document into tables and regular text,\n",
    "    ensuring that ongoing tables are merged properly.\n",
    "    \"\"\"\n",
    "    sections = re.split(r\"(##TABLE_START|##TABLE_END)\", document)\n",
    "    chunks = []\n",
    "    current_table = []\n",
    "    last_text = \"\"\n",
    "    in_table = False\n",
    "    for section in sections:\n",
    "        section = section.strip()\n",
    "        if section == \"##TABLE_START\":\n",
    "            if in_table:\n",
    "                pass\n",
    "            else:\n",
    "                in_table = True\n",
    "                current_table = []\n",
    "        elif section == \"##TABLE_END\":\n",
    "            if in_table:\n",
    "                in_table = False\n",
    "                table_chunk = \"\".join(current_table)\n",
    "                chunks.append(last_text.strip() + table_chunk)\n",
    "                last_text = \"\"\n",
    "        else:\n",
    "            if in_table:\n",
    "                current_table.append(section)\n",
    "            else:\n",
    "                last_text += section\n",
    "\n",
    "    if in_table:\n",
    "        table_chunk = \"\".join(current_table)\n",
    "        chunks.append(last_text.strip() + table_chunk)\n",
    "\n",
    "    output = []\n",
    "    for i in chunks:\n",
    "        i = i.replace(\"\\n\", \" \")  # Replace newlines with spaces\n",
    "        i = i.replace(\"\\xa0\", \" \")  # Replace non-breaking spaces with regular spaces\n",
    "\n",
    "        # Split text into sentences if it's too long\n",
    "        if len(i) > 3000:\n",
    "            sentences = split_into_sentences(i)\n",
    "            sub_chunk = \"\"\n",
    "            for sentence in sentences:\n",
    "                if len(sub_chunk) + len(sentence) > chunk_size_limit:\n",
    "                    # If adding this sentence exceeds 3000 characters, by default, save the current sub-chunk and start a new one  # noqa: E501\n",
    "                    output.append(sub_chunk.strip())\n",
    "                    sub_chunk = sentence  # Start a new chunk with the current sentence\n",
    "                else:\n",
    "                    # Add the sentence to the current sub-chunk\n",
    "                    sub_chunk += \" \" + sentence\n",
    "            # Append the last sub-chunk if it exists\n",
    "            if sub_chunk:\n",
    "                output.append(sub_chunk.strip())\n",
    "        else:\n",
    "            output.append(i)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = separate_tables_from_text(documents[2][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below, re-organizing the documents with the newly created chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents = []\n",
    "for i in documents:\n",
    "    chunks = separate_tables_from_text(i[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        new_documents.append(\n",
    "            {\n",
    "                \"company\": i[\"company\"],\n",
    "                \"reporting_period\": i[\"reporting_period\"],\n",
    "                \"filing_type\": i[\"filing_type\"],\n",
    "                \"section\": i[\"section\"],\n",
    "                \"text\": chunk,\n",
    "                \"id\": parsing.generate_document_id(i[\"id\"] + chunk[-100:]),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/documents_chunked_3000.json\", \"w\") as f:\n",
    "    json.dump(new_documents, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"company\": \"pltr\",\n",
      "    \"reporting_period\": \"2023-12-31\",\n",
      "    \"filing_type\": \"10k\",\n",
      "    \"section\": \"md_a\",\n",
      "    \"text\": \"ITEM 7. MANAGEMENT\\u2019S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS   The following discussion and analysis of our financial condition and results of operations should be read in conjunction with our consolidated financial statements and the accompanying notes thereto included elsewhere in this Annual Report on Form 10-K. This discussion contains forward-looking statements based upon current plans, expectations, and beliefs, involving risks and uncertainties. Our actual results may differ materially from those anticipated in these forward-looking statements. You should review the section titled \\u201cSpecial Note Regarding Forward-Looking Statements\\u201d for a discussion of forward-looking statements and the section titled \\u201cRisk Factors\\u201d for a discussion of factors that could cause actual results to differ materially from the results described in or implied by the forward-looking statements contained in the following discussion and analysis and elsewhere in this Annual Report on Form 10-K. Our historical results are not necessarily indicative of the results that may be expected for any period in the future. This section of this Annual Report on Form 10-K generally discusses fiscal years 2023 and 2022 items and year-to-year comparisons between fiscal years 2023 and 2022. Discussions of fiscal year 2022 items and year-to-year comparisons between fiscal years 2022 and 2021 that are not included in this Annual Report on Form 10-K can be found in Part II, Item 7, \\u201cManagement\\u2019s Discussion and Analysis of Financial Condition and Results of Operations\\u201d of our Annual Report on Form 10-K for the fiscal year ended December 31, 2022, which was filed with the SEC on February 21, 2023 and is incorporated herein by reference. Overview   We build software that empowers organizations to effectively integrate their data, decisions, and operations at scale. We were founded in 2003 and started building software for the intelligence community in the United States to assist in counterterrorism investigations and operations. We later began working with commercial enterprises, who often faced fundamentally similar challenges in working with data. We have built four principal software platforms, Gotham, Foundry, Apollo, and our Artificial Intelligence Platform (\\u201cAIP\\u201d). Gotham and Foundry enable institutions to transform massive amounts of information into an integrated data asset that reflects their operations, and AIP leverages the power of our existing machine learning technologies alongside large language models (\\u201cLLMs\\u201d) directly within Gotham and/or Foundry to help connect AI to enterprise data. For over a decade, Gotham has surfaced insights for global defense agencies, the intelligence community, disaster relief organizations and beyond. Foundry is   becoming a central operating system not only for individual institutions but also for entire industries.\",\n",
      "    \"id\": \"7bfe3d16\"\n",
      "  },\n",
      "  {\n"
     ]
    }
   ],
   "source": [
    "!head data/documents_chunked_3000.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below:\n",
    "- Chunk out tables (same as above)\n",
    "- If text is longer than 200 characters, stop at the last sentence before exceeding the 200th character and start a new chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents_500 = []\n",
    "for i in documents:\n",
    "    chunks = separate_tables_from_text(i[\"text\"], chunk_size_limit=500)\n",
    "    for n, chunk in enumerate(chunks):\n",
    "        if len(chunk):\n",
    "            new_documents_500.append(\n",
    "                {\n",
    "                    \"company\": i[\"company\"],\n",
    "                    \"reporting_period\": i[\"reporting_period\"],\n",
    "                    \"filing_type\": i[\"filing_type\"],\n",
    "                    \"section\": i[\"section\"],\n",
    "                    \"text\": chunk,\n",
    "                    \"id\": parsing.generate_document_id(str(n) + i[\"id\"]),\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/documents_chunked_500.json\", \"w\") as f:\n",
    "    json.dump(new_documents_500, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"company\": \"pltr\",\n",
      "    \"reporting_period\": \"2023-12-31\",\n",
      "    \"filing_type\": \"10k\",\n",
      "    \"section\": \"md_a\",\n",
      "    \"text\": \"ITEM 7. MANAGEMENT\\u2019S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS   The following discussion and analysis of our financial condition and results of operations should be read in conjunction with our consolidated financial statements and the accompanying notes thereto included elsewhere in this Annual Report on Form 10-K. This discussion contains forward-looking statements based upon current plans, expectations, and beliefs, involving risks and uncertainties.\",\n",
      "    \"id\": \"d404ce24\"\n",
      "  },\n",
      "  {\n"
     ]
    }
   ],
   "source": [
    "!head data/documents_chunked_500.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"##TABLE_START\", \"##TABLE_END\", \"\\n\\n\"]\n",
    "ss = [\n",
    "    i\n",
    "    for i in re.split(r\"(##TABLE_START|##TABLE_END)\", documents[2][\"text\"])\n",
    "    if i not in tags\n",
    "]\n",
    "# [i.replace(\"\\n\\n\", \"\") for i in ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences_by_period(text):\n",
    "    text = text.replace(\" \\n\\n\", \". \")\n",
    "    abbreviations = (\n",
    "        r\"(Inc|Ltd|Dr|Mr|Ms|Mrs|Jr|Sr|No|e\\.g|U\\.S|U\\.K|PCAOB|BOD|etc| v| al)\\.\"\n",
    "    )\n",
    "\n",
    "    # First, replace periods in abbreviations and other common uses (like decimals) with placeholders  # noqa: E501\n",
    "    text = re.sub(abbreviations, lambda m: m.group(0).replace(\".\", \"|||\"), text)\n",
    "\n",
    "    # Now, split text by periods that could indicate sentence boundaries.\n",
    "    # This regex matches periods that are not part of abbreviations or decimals\n",
    "    sentence_endings = re.compile(\n",
    "        r\"\"\"\n",
    "        (?<!\\d)\\.              # Ensure we're not in a decimal number (no digit before period)\n",
    "        (?!\\d)                  # Ensure we're not in a decimal number (no digit after period)\n",
    "        (?=\\s|\\n|$)             # The period is followed by a space, newline, or end of string\n",
    "    \"\"\",\n",
    "        re.VERBOSE,\n",
    "    )  # noqa: E501\n",
    "\n",
    "    # Split text using the sentence-ending regex\n",
    "    sentences = sentence_endings.split(text)\n",
    "\n",
    "    # Replace the placeholders back to actual periods\n",
    "    sentences = [s.replace(\"|||\", \".\") for s in sentences]\n",
    "\n",
    "    # Clean up extra whitespace and remove any empty sentences\n",
    "    stripped = [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def create_overlapping_chunks(text: str, overlap: int = 5) -> list:\n",
    "    tags = [\"##TABLE_START\", \"##TABLE_END\", \"\\n\\n\"]\n",
    "    tag_splits = [\n",
    "        i for i in re.split(r\"(##TABLE_START|##TABLE_END)\", text) if i not in tags\n",
    "    ]\n",
    "    splits = [split_into_sentences_by_period(i) for i in tag_splits]\n",
    "    flattened_list = list(itertools.chain(*splits))\n",
    "\n",
    "    new_flat_list = []\n",
    "    i = 0\n",
    "    # for i in range(len(flattened_list)):\n",
    "    while i < len(flattened_list) - overlap:\n",
    "        init_string = \"\"\n",
    "        for j in flattened_list[i : i + overlap]:\n",
    "            init_string += j + \". \"\n",
    "        new_flat_list.append(init_string)\n",
    "        i += 1\n",
    "    return new_flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = create_overlapping_chunks(documents[2][\"text\"], overlap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_documents_5s = []\n",
    "for i in documents:\n",
    "    chunks = create_overlapping_chunks(i[\"text\"], overlap=5)\n",
    "    for n, chunk in enumerate(chunks):\n",
    "        if len(chunk):\n",
    "            new_documents_5s.append(\n",
    "                {\n",
    "                    \"company\": i[\"company\"],\n",
    "                    \"reporting_period\": i[\"reporting_period\"],\n",
    "                    \"filing_type\": i[\"filing_type\"],\n",
    "                    \"section\": i[\"section\"],\n",
    "                    \"text\": chunk,\n",
    "                    \"id\": parsing.generate_document_id(str(n) + i[\"id\"]),\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/documents_chunked_5s.json\", \"w\") as f:\n",
    "    json.dump(new_documents_5s, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = documents[2][\"text\"].find(\n",
    "    \"To date, the Company has not been required to make any payment resulting from\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_formatting_example = \"December 31, 2023, 2022, and 2021 was $ 526.1 million, $ 453.2 million, and $ 421.0 million, respectively\"  # noqa: E501\n",
    "date_formatting_example = \"As of December 31, 2023 As of December 31, 2022 Authorized Issued and Outstanding Authorized Issued and Outstanding Class A Common Stock 20,000,000 \\xa0 2,096,982 \\xa0 20,000,000 \\xa0 1,995,414 \\xa0 Class B Common Stock 2,700,000 \\xa0 102,141 \\xa0 2,700,000 \\xa0 102,656 \\xa0 Class F Common Stock 1,005 \\xa0 1,005 \\xa0 1,005 \\xa0 1,005 \\xa0 Total 22,701,005 \\xa0 2,200,128 \\xa0 22,701,005 \\xa0 2,099,075'\"  # noqa: E501\n",
    "date_formatting_example = \"'Years Ended December 31, 2023 2022 Cash paid for operating lease liabilities $ 63,374 \\xa0 $ 53,772 ,Lease liabilities arising from obtaining right-of-use assets,'$ 28,112 \\xa0 $ 28,169'\"  # noqa: E501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
